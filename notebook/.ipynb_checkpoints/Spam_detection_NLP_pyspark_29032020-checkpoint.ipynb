{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.4.5-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, Tokenizer, RegexTokenizer, StopWordsRemover, NGram\n",
    "from pyspark.ml.feature import HashingTF, IDF, CountVectorizer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.sql.types import IntegerType\n",
    "import os\n",
    "os.chdir('/home/ubuntu/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('spam_detection').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('SMSSpamCollection', inferSchema=True, sep='\\t') \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='ham', _c1='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'),\n",
       " Row(_c0='ham', _c1='Ok lar... Joking wif u oni...'),\n",
       " Row(_c0='spam', _c1=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(class='ham', text='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'),\n",
       " Row(class='ham', text='Ok lar... Joking wif u oni...'),\n",
       " Row(class='spam', text=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumnRenamed('_c0', 'class').withColumnRenamed('_c1', 'text')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "|  ham|I'm gonna be home...|\n",
      "| spam|SIX chances to wi...|\n",
      "| spam|URGENT! You have ...|\n",
      "|  ham|I've been searchi...|\n",
      "|  ham|I HAVE A DATE ON ...|\n",
      "| spam|XXXMobileMovieClu...|\n",
      "|  ham|Oh k...i'm watchi...|\n",
      "|  ham|Eh u remember how...|\n",
      "|  ham|Fine if thats th...|\n",
      "| spam|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "|  ham|I'm gonna be home...|   109|\n",
      "| spam|SIX chances to wi...|   136|\n",
      "| spam|URGENT! You have ...|   155|\n",
      "|  ham|I've been searchi...|   196|\n",
      "|  ham|I HAVE A DATE ON ...|    35|\n",
      "| spam|XXXMobileMovieClu...|   149|\n",
      "|  ham|Oh k...i'm watchi...|    26|\n",
      "|  ham|Eh u remember how...|    81|\n",
      "|  ham|Fine if thats th...|    56|\n",
      "| spam|England v Macedon...|   155|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('length', length(df['text']))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(length)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('class').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokken = Tokenizer(inputCol='text', outputCol='token_text')\n",
    "remover = StopWordsRemover(inputCol=\"token_text\", outputCol=\"stop_token\")\n",
    "cv = CountVectorizer(inputCol='stop_token', outputCol='c_vec', vocabSize=3, minDF=2.0)\n",
    "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\n",
    "ham_spam_to_num = StringIndexer(inputCol='class', outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['length', 'tf_idf'], outputCol='features')\n",
    "nb =  NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+-----+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|class|                text|length|label|          token_text|          stop_token|              c_vec|              tf_idf|            features|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|          (3,[],[])|           (3,[],[])|     (4,[0],[111.0])|\n",
      "|  ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|      (3,[0],[1.0])|(3,[0],[2.0166983...|[29.0,2.016698353...|\n",
      "| spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|      (3,[2],[1.0])|(3,[2],[2.7044691...|[155.0,0.0,0.0,2....|\n",
      "|  ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|      (3,[0],[2.0])|(3,[0],[4.0333967...|[49.0,4.033396706...|\n",
      "|  ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|          (3,[],[])|           (3,[],[])|      (4,[0],[61.0])|\n",
      "| spam|FreeMsg Hey there...|   147|  1.0|[freemsg, hey, th...|[freemsg, hey, da...|          (3,[],[])|           (3,[],[])|     (4,[0],[147.0])|\n",
      "|  ham|Even my brother i...|    77|  0.0|[even, my, brothe...|[even, brother, l...|          (3,[],[])|           (3,[],[])|      (4,[0],[77.0])|\n",
      "|  ham|As per your reque...|   160|  0.0|[as, per, your, r...|[per, request, 'm...|          (3,[],[])|           (3,[],[])|     (4,[0],[160.0])|\n",
      "| spam|WINNER!! As a val...|   157|  1.0|[winner!!, as, a,...|[winner!!, valued...|      (3,[1],[1.0])|(3,[1],[2.3645559...|[157.0,0.0,2.3645...|\n",
      "| spam|Had your mobile 1...|   154|  1.0|[had, your, mobil...|[mobile, 11, mont...|(3,[0,1],[1.0,1.0])|(3,[0,1],[2.01669...|[154.0,2.01669835...|\n",
      "|  ham|I'm gonna be home...|   109|  0.0|[i'm, gonna, be, ...|[gonna, home, soo...|          (3,[],[])|           (3,[],[])|     (4,[0],[109.0])|\n",
      "| spam|SIX chances to wi...|   136|  1.0|[six, chances, to...|[six, chances, wi...|          (3,[],[])|           (3,[],[])|     (4,[0],[136.0])|\n",
      "| spam|URGENT! You have ...|   155|  1.0|[urgent!, you, ha...|[urgent!, won, 1,...|          (3,[],[])|           (3,[],[])|     (4,[0],[155.0])|\n",
      "|  ham|I've been searchi...|   196|  0.0|[i've, been, sear...|[searching, right...|          (3,[],[])|           (3,[],[])|     (4,[0],[196.0])|\n",
      "|  ham|I HAVE A DATE ON ...|    35|  0.0|[i, have, a, date...|[date, sunday, wi...|          (3,[],[])|           (3,[],[])|      (4,[0],[35.0])|\n",
      "| spam|XXXMobileMovieClu...|   149|  1.0|[xxxmobilemoviecl...|[xxxmobilemoviecl...|          (3,[],[])|           (3,[],[])|     (4,[0],[149.0])|\n",
      "|  ham|Oh k...i'm watchi...|    26|  0.0|[oh, k...i'm, wat...|[oh, k...i'm, wat...|          (3,[],[])|           (3,[],[])|      (4,[0],[26.0])|\n",
      "|  ham|Eh u remember how...|    81|  0.0|[eh, u, remember,...|[eh, u, remember,...|(3,[0,2],[1.0,1.0])|(3,[0,2],[2.01669...|[81.0,2.016698353...|\n",
      "|  ham|Fine if thats th...|    56|  0.0|[fine, if, thats...|[fine, thats, wa...|      (3,[0],[1.0])|(3,[0],[2.0166983...|[56.0,2.016698353...|\n",
      "| spam|England v Macedon...|   155|  1.0|[england, v, mace...|[england, v, mace...|          (3,[],[])|           (3,[],[])|     (4,[0],[155.0])|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pipeline = Pipeline(stages=[ham_spam_to_num, tokken, remover, cv, idf, assembler])\n",
    "clean_df = data_pipeline.fit(df).transform(df)\n",
    "clean_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'text',\n",
       " 'length',\n",
       " 'label',\n",
       " 'token_text',\n",
       " 'stop_token',\n",
       " 'c_vec',\n",
       " 'tf_idf',\n",
       " 'features']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|     (4,[0],[111.0])|\n",
      "|  0.0|[29.0,2.016698353...|\n",
      "|  1.0|[155.0,0.0,0.0,2....|\n",
      "|  0.0|[49.0,4.033396706...|\n",
      "|  0.0|      (4,[0],[61.0])|\n",
      "|  1.0|     (4,[0],[147.0])|\n",
      "|  0.0|      (4,[0],[77.0])|\n",
      "|  0.0|     (4,[0],[160.0])|\n",
      "|  1.0|[157.0,0.0,2.3645...|\n",
      "|  1.0|[154.0,2.01669835...|\n",
      "|  0.0|     (4,[0],[109.0])|\n",
      "|  1.0|     (4,[0],[136.0])|\n",
      "|  1.0|     (4,[0],[155.0])|\n",
      "|  0.0|     (4,[0],[196.0])|\n",
      "|  0.0|      (4,[0],[35.0])|\n",
      "|  1.0|     (4,[0],[149.0])|\n",
      "|  0.0|      (4,[0],[26.0])|\n",
      "|  0.0|[81.0,2.016698353...|\n",
      "|  0.0|[56.0,2.016698353...|\n",
      "|  1.0|     (4,[0],[155.0])|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df = clean_df.select(['label', 'features'])\n",
    "clean_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = clean_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+--------------------+--------------------+----------+\n",
      "|label|      features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------+--------------------+--------------------+----------+\n",
      "|  0.0| (4,[0],[2.0])|[-0.1633426714819...|[0.86573581892816...|       0.0|\n",
      "|  0.0| (4,[0],[2.0])|[-0.1633426714819...|[0.86573581892816...|       0.0|\n",
      "|  0.0| (4,[0],[2.0])|[-0.1633426714819...|[0.86573581892816...|       0.0|\n",
      "|  0.0| (4,[0],[2.0])|[-0.1633426714819...|[0.86573581892816...|       0.0|\n",
      "|  0.0| (4,[0],[3.0])|[-0.1722403132750...|[0.86632596636606...|       0.0|\n",
      "|  0.0| (4,[0],[5.0])|[-0.1900355968613...|[0.86749968033705...|       0.0|\n",
      "|  0.0| (4,[0],[5.0])|[-0.1900355968613...|[0.86749968033705...|       0.0|\n",
      "|  0.0| (4,[0],[5.0])|[-0.1900355968613...|[0.86749968033705...|       0.0|\n",
      "|  0.0| (4,[0],[6.0])|[-0.1989332386544...|[0.86808325621570...|       0.0|\n",
      "|  0.0| (4,[0],[7.0])|[-0.2078308804476...|[0.86866465095614...|       0.0|\n",
      "|  0.0| (4,[0],[7.0])|[-0.2078308804476...|[0.86866465095614...|       0.0|\n",
      "|  0.0| (4,[0],[9.0])|[-0.2256261640338...|[0.86982091594811...|       0.0|\n",
      "|  0.0|(4,[0],[10.0])|[-0.2345238058269...|[0.87039579571414...|       0.0|\n",
      "|  0.0|(4,[0],[11.0])|[-0.2434214476201...|[0.87096851337027...|       0.0|\n",
      "|  0.0|(4,[0],[11.0])|[-0.2434214476201...|[0.87096851337027...|       0.0|\n",
      "|  0.0|(4,[0],[12.0])|[-0.2523190894132...|[0.87153907372388...|       0.0|\n",
      "|  0.0|(4,[0],[13.0])|[-0.2612167312063...|[0.87210748160179...|       0.0|\n",
      "|  0.0|(4,[0],[13.0])|[-0.2612167312063...|[0.87210748160179...|       0.0|\n",
      "|  0.0|(4,[0],[13.0])|[-0.2612167312063...|[0.87210748160179...|       0.0|\n",
      "|  0.0|(4,[0],[13.0])|[-0.2612167312063...|[0.87210748160179...|       0.0|\n",
      "+-----+--------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_detector = nb.fit(train)\n",
    "test_results = spam_detector.transform(test)\n",
    "test_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB model :  0.8752057071803889\n"
     ]
    }
   ],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print('Accuracy of NB model : ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
